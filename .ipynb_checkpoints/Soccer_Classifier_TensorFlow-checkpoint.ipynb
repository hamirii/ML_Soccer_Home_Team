{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple machine learning program on Serie A 2018/19 Season Stats - Using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a general function that will take a dataset of football/soccer results and output the number of wins, draws, and losses. Note that the 'data' should be in Panda DataFrame format, with FTR being a category/heading of a column. In our datasets, this is a given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function that isolates the full time result to see record of wins/losses/draws\n",
    "\n",
    "def winRecords(data, leagueName):\n",
    "    \n",
    "    ftr = data['FTR']\n",
    "\n",
    "    homeWins=0\n",
    "    awayWins=0\n",
    "    draws=0\n",
    "    \n",
    "    for i in range(0, len(ftr.to_numpy())-1):\n",
    "    \n",
    "        if (ftr.to_numpy()[i] == 'H'):\n",
    "            homeWins += 1\n",
    "            #print(j)\n",
    "        elif (ftr.to_numpy()[i] == 'A'):\n",
    "            awayWins += 1\n",
    "        else:\n",
    "            draws +=1\n",
    "\n",
    "    return leagueName, 'HomeWins: %s' % homeWins, 'Away Wins: %s' % awayWins, 'Draws: %s' % draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the files and print out the stats for Serie A leagues in several seasons (and the EPL season)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SerieA_15_16', 'HomeWins: 175', 'Away Wins: 109', 'Draws: 95')\n",
      "('SerieA_16_17', 'HomeWins: 183', 'Away Wins: 116', 'Draws: 80')\n",
      "('SerieA_18_19', 'HomeWins: 165', 'Away Wins: 106', 'Draws: 108')\n",
      "('EPL_18_19', 'HomeWins: 181', 'Away Wins: 127', 'Draws: 71')\n"
     ]
    }
   ],
   "source": [
    "print(winRecords(pd.read_csv(\"serieA_season-1516.csv\"), 'SerieA_15_16'))\n",
    "print(winRecords(pd.read_csv(\"serieA_season-1617.csv\"), 'SerieA_16_17'))\n",
    "print(winRecords(pd.read_csv(\"serieA_season-1819.csv\"), 'SerieA_18_19'))\n",
    "print(winRecords(pd.read_csv(\"epl_season-1819.csv\"), 'EPL_18_19'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start training/learning/evaluating/testing our Model\n",
    "\n",
    "Beginning with Serie A 2018/19 dataset, we must first 'clean' the data. This is done by dropping the useless categories. In our case, this is the division and the date of the games. We don't care when the games were played (they're already ordered chronologically), but who played whom and when. We also want to drop the Full Time Home and Away Goals Scored and the Half Time Result categories, as these will obviously influence our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSerieA1819 = pd.read_csv(\"serieA_season-1819Dd.csv\")\n",
    "dataSerieA1819 = dataSerieA1819.drop('Div', axis=1)\n",
    "dataSerieA1819 = dataSerieA1819.drop('Date', axis=1)\n",
    "\n",
    "# Dropping the Full Time Home Goals Scored, FTAG, and the Half time result\n",
    "\n",
    "dataSerieA1819 = dataSerieA1819.drop('FTAG', axis=1)\n",
    "dataSerieA1819 = dataSerieA1819.drop('FTHG', axis=1)\n",
    "dataSerieA1819 = dataSerieA1819.drop('HTR', axis=1)\n",
    "\n",
    "# Dropping the Half Time Home Goals Scored, FTAG, and the Half time result\n",
    "\n",
    "dataSerieA1819 = dataSerieA1819.drop('HTHG', axis=1)\n",
    "dataSerieA1819 = dataSerieA1819.drop('HTAG', axis=1)\n",
    "\n",
    "dataSerieA1819['FTR'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a look at the column of interest, which is FTR (Full Time Result), and change it to 0s and 1s for our system to be able to classify/predict these outcomes easily. 0 if the Home Team draws or loses, 1 if the Home Team wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the string for Full Time Result (FTR), AKA the outcome to 0s and 1s. 1 if the Home Team wins, 0 if the Away Team won or if a Draw was achieved\n",
    "\n",
    "def fix_outcome(outcome):\n",
    "    if outcome == 'H':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "dataSerieA1819['FTR'] = dataSerieA1819['FTR'].apply(fix_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the train_test_split function from the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can Train_Test_Split our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split Data\n",
    "\n",
    "x_data = dataSerieA1819.drop('FTR', axis=1)\n",
    "y_labels = dataSerieA1819['FTR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import TensorFlow package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the feature columns. In this notebook, this is split up into a section for the categorical values, and a section for the continuous/numerical values. This is because they use different lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf.feature_columns for Categorical Values\n",
    "\n",
    "HomeTeam = tf.feature_column.categorical_column_with_hash_bucket('HomeTeam', hash_bucket_size=1000)\n",
    "AwayTeam = tf.feature_column.categorical_column_with_hash_bucket('AwayTeam', hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for these values, there is not an 'FTR' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf.feature_columns for Numerical/Continuous Values\n",
    "\n",
    "HS   = tf.feature_column.numeric_column('HS')   # Home Shots\n",
    "AS   = tf.feature_column.numeric_column('AS')   # Away Shots\n",
    "HST  = tf.feature_column.numeric_column('HST')  # Home Shots on Target\n",
    "AST  = tf.feature_column.numeric_column('AST')  # Away Shots on Target\n",
    "HF  = tf.feature_column.numeric_column('HF')    # Home Fouls\n",
    "AF  = tf.feature_column.numeric_column('AF')    # Away Fouls\n",
    "HC  = tf.feature_column.numeric_column('HC')    # Home Corners\n",
    "AC  = tf.feature_column.numeric_column('AC')    # Away Corners\n",
    "HY  = tf.feature_column.numeric_column('HY')    # Home Yellow Cards\n",
    "AY  = tf.feature_column.numeric_column('AY')    # Away Yellow Cards\n",
    "HR  = tf.feature_column.numeric_column('HR')    # Home Red Cards\n",
    "AR  = tf.feature_column.numeric_column('AR')    # Away Red Cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile into one features column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile into one features column\n",
    "\n",
    "feature_cols = [HomeTeam,AwayTeam,FTHG,FTAG,HTHG,HTAG,HTR,HS,AS,HST,AST,HF,AF,HC,AC,HY,AY,HR,AR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tensor flow estimator method, let's build our input function. Note that the batch_size is 100 and the number of epochs is \"None\". The batch size is the number of samples that are processed before updating the model, while the epochs are the number of complete passes through the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an input function\n",
    "\n",
    "input_fnc = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=100, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
